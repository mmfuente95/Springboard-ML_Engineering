{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c92331d",
   "metadata": {},
   "source": [
    "# Deep Learning Translator - Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c743cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9257a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the most repeated words in both dataset\n",
    "rosetta_bible = pd.read_csv('french_and_english_vocab.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de012a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# English Sentences\n",
    "english_sentences = rosetta_bible.English\n",
    "# Quechua Sentences\n",
    "quechua_sentences = rosetta_bible.Quechua\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e66df1",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96fead13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    x_tk = Tokenizer(char_level = False)\n",
    "    x_tk.fit_on_texts(x)\n",
    "    return x_tk.texts_to_sequences(x), x_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b57f8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    return pad_sequences(x, maxlen = length, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a24b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "    \n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "# Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "preproc_english_sentences, preproc_quechua_sentences, english_tokenizer, quechua_tokenizer = preprocess(english_sentences, quechua_sentences)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b52bda52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "    print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe942c",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2b6cdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Loaded\n"
     ]
    }
   ],
   "source": [
    "def model_final(input_shape, output_sequence_length, english_vocab_size, quechua_vocab_size):\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=english_vocab_size,output_dim=128,input_length=input_shape[1]))\n",
    "    model.add(Bidirectional(GRU(256,return_sequences=False)))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    model.add(Bidirectional(GRU(256,return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(quechua_vocab_size,activation='softmax')))\n",
    "    learning_rate = 0.005\n",
    "    \n",
    "    model.compile(loss = sparse_categorical_crossentropy, \n",
    "                 optimizer = Adam(learning_rate), \n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "print('Final Model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecccde11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "276/276 [==============================] - 469s 2s/step - loss: 1.3746 - accuracy: 0.6587 - val_loss: 0.6339 - val_accuracy: 0.8089\n",
      "Epoch 2/5\n",
      "276/276 [==============================] - 515s 2s/step - loss: 0.3574 - accuracy: 0.8924 - val_loss: 0.2486 - val_accuracy: 0.9256\n",
      "Epoch 3/5\n",
      "276/276 [==============================] - 530s 2s/step - loss: 0.1922 - accuracy: 0.9422 - val_loss: 0.1520 - val_accuracy: 0.9537\n",
      "Epoch 4/5\n",
      "276/276 [==============================] - 530s 2s/step - loss: 0.1421 - accuracy: 0.9564 - val_loss: 0.1365 - val_accuracy: 0.9586\n",
      "Epoch 5/5\n",
      "276/276 [==============================] - 491s 2s/step - loss: 0.1097 - accuracy: 0.9664 - val_loss: 0.1029 - val_accuracy: 0.9696\n"
     ]
    }
   ],
   "source": [
    "def final_predictions(x, y, x_tk, y_tk):\n",
    "    tmp_X = pad(preproc_english_sentences)\n",
    "    model = model_final(tmp_X.shape,\n",
    "                        preproc_quechua_sentences.shape[1],\n",
    "                        len(english_tokenizer.word_index)+1,\n",
    "                        len(quechua_tokenizer.word_index)+1)\n",
    "    \n",
    "    model.fit(tmp_X, preproc_quechua_sentences, batch_size = 400, epochs = 5, validation_split = 0.2)\n",
    "    \n",
    "    fitted_model = model\n",
    "    return fitted_model\n",
    "   \n",
    "fitted_model = final_predictions(preproc_english_sentences, preproc_quechua_sentences, english_tokenizer, quechua_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39330728",
   "metadata": {},
   "source": [
    "# Write fitted model as JSON\n",
    "After fully training the model we can write an H5 file with all the ideal parameters which will then be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8a61ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model.save_weights('model_weights.h5')\n",
    "json_string = fitted_model.to_json()\n",
    "f = open(\"model_architecture.json\",'w')\n",
    "f.write(json_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdbcda3",
   "metadata": {},
   "source": [
    "# Open fitted Model\n",
    "We can open the fitted model using the protocol below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c1b19ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"model_architecture.json\",'r+')\n",
    "json_string = f.read()\n",
    "f.close()\n",
    "model = model_from_json(json_string)\n",
    "model.load_weights('model_weights.h5')\n",
    "model.compile(loss=sparse_categorical_crossentropy, optimizer=Adam(0.005), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d96cfbd",
   "metadata": {},
   "source": [
    "# Full Prediction Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a561250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    x_tk = Tokenizer(char_level = False)\n",
    "    x_tk.fit_on_texts(x)\n",
    "    return x_tk.texts_to_sequences(x), x_tk\n",
    "\n",
    "def pad(x, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    return pad_sequences(x, maxlen = length, padding = 'post')\n",
    "\n",
    "def preprocess(x, y):\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "    \n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "# Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "preproc_english_sentences, preproc_quechua_sentences, english_tokenizer, quechua_tokenizer = preprocess(english_sentences, quechua_sentences)\n",
    "    \n",
    "def logits_to_text(logits, tokenizer):\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "    print('`logits_to_text` function loaded.') \n",
    "\n",
    "    \n",
    "def run(English_Phrase):\n",
    "    K.clear_session()\n",
    "    rosetta_bible = pd.read_csv('french_and_english_vocab.csv')\n",
    "    # English Sentences\n",
    "    english_sentences = rosetta_bible.English\n",
    "    # Quechua Sentences\n",
    "    quechua_sentences = rosetta_bible.Quechua    \n",
    "    preproc_english_sentences, preproc_quechua_sentences, english_tokenizer, quechua_tokenizer = preprocess(english_sentences, quechua_sentences)\n",
    "    y_id_to_word = {value: key for key, value in quechua_tokenizer.word_index.items()}\n",
    "    y_id_to_word[0] = '<PAD>'\n",
    "    sentence = English_Phrase\n",
    "#     sentence = 'his favorite fruit is orange'\n",
    "    sentence = [english_tokenizer.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=preproc_english_sentences.shape[-1], padding='post')\n",
    "    sentence\n",
    "    sentences = np.array([sentence[0], preproc_english_sentences[0]])\n",
    "    \n",
    "    f = open(\"model_architecture.json\",'r+')\n",
    "    json_string = f.read()\n",
    "    f.close()\n",
    "    model = model_from_json(json_string)\n",
    "    model.load_weights('model_weights.h5')\n",
    "    model.compile(loss=sparse_categorical_crossentropy, optimizer=Adam(0.005), metrics=['accuracy'])         \n",
    "\n",
    "    predictions = model.predict(sentences, len(sentences))\n",
    "    final_pred = ' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]])\n",
    "    final_pred = final_pred.replace(\"<PAD>\",\"\")\n",
    "    return final_pred\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcef335b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'son fruit préféré est le pamplemousse               '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run('his favorite fruit is grapefruit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c4680",
   "metadata": {},
   "source": [
    "# BLEU Score Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3777a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [np.random.randint(len(rosetta_bible), size=10)]\n",
    "empty_list_english = pd.DataFrame([])\n",
    "empty_list_french = pd.DataFrame([])\n",
    "for i in index_list:\n",
    "    a = empty_list.append(rosetta_bible['English'][i])\n",
    "    b = empty_list.append(rosetta_bible['Quechua'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "861911c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59124</th>\n",
       "      <td>paris is sometimes wonderful during december ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77029</th>\n",
       "      <td>paris is usually chilly during fall , but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31930</th>\n",
       "      <td>the banana is their least favorite fruit , but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50956</th>\n",
       "      <td>california is usually snowy during april , and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112496</th>\n",
       "      <td>the lime is her most loved fruit , but the man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61308</th>\n",
       "      <td>paris is usually freezing during september , b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91526</th>\n",
       "      <td>the apple is my least liked fruit , but the st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101651</th>\n",
       "      <td>new jersey is never rainy during winter , and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78490</th>\n",
       "      <td>he drove the little yellow truck .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73234</th>\n",
       "      <td>new jersey is usually relaxing during march , ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  English\n",
       "59124   paris is sometimes wonderful during december ,...\n",
       "77029   paris is usually chilly during fall , but it i...\n",
       "31930   the banana is their least favorite fruit , but...\n",
       "50956   california is usually snowy during april , and...\n",
       "112496  the lime is her most loved fruit , but the man...\n",
       "61308   paris is usually freezing during september , b...\n",
       "91526   the apple is my least liked fruit , but the st...\n",
       "101651  new jersey is never rainy during winter , and ...\n",
       "78490                  he drove the little yellow truck .\n",
       "73234   new jersey is usually relaxing during march , ..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the candidate english phrases\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d56df4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59124</th>\n",
       "      <td>paris est parfois merveilleux en décembre , ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77029</th>\n",
       "      <td>paris est généralement froid à l'automne , mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31930</th>\n",
       "      <td>la banane est leur fruit préféré moins , mais ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50956</th>\n",
       "      <td>californie est généralement enneigée en avril ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112496</th>\n",
       "      <td>la chaux est son fruit le plus aimé , mais la ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61308</th>\n",
       "      <td>paris est le gel habituellement en septembre ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91526</th>\n",
       "      <td>la pomme est mon moins aimé des fruits , mais ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101651</th>\n",
       "      <td>new jersey est jamais pluvieux pendant l' hive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78490</th>\n",
       "      <td>il a conduit le petit camion jaune .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73234</th>\n",
       "      <td>new jersey est relaxant habituellement en mars...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Quechua\n",
       "59124   paris est parfois merveilleux en décembre , ma...\n",
       "77029   paris est généralement froid à l'automne , mai...\n",
       "31930   la banane est leur fruit préféré moins , mais ...\n",
       "50956   californie est généralement enneigée en avril ...\n",
       "112496  la chaux est son fruit le plus aimé , mais la ...\n",
       "61308   paris est le gel habituellement en septembre ,...\n",
       "91526   la pomme est mon moins aimé des fruits , mais ...\n",
       "101651  new jersey est jamais pluvieux pendant l' hive...\n",
       "78490                il a conduit le petit camion jaune .\n",
       "73234   new jersey est relaxant habituellement en mars..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the reference french phrases\n",
    "b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a1502f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paris', 'est', 'parfois', 'merveilleux', 'en', 'décembre', 'mais', 'il', 'est', 'relaxant', 'à', \"l'\", 'automne']\n",
      "['paris', 'est', 'parfois', 'merveilleux', 'en', 'décembre', 'mais', 'il', 'est', 'relaxant', 'à', 'l', 'automne']\n",
      "0.842362674378975\n",
      "['paris', 'est', 'généralement', 'froid', 'à', \"l'automne\", 'mais', 'il', 'est', 'jamais', 'chaud', 'en', 'janvier']\n",
      "['paris', 'est', 'généralement', 'froid', 'à', 'l', 'automne', 'mais', 'il', 'est', 'jamais', 'chaud', 'en', 'janvier']\n",
      "0.7048050905062194\n",
      "['la', 'banane', 'est', 'leur', 'fruit', 'préféré', 'moins', 'mais', \"l'orange\", 'est', 'son', 'moins', 'préféré']\n",
      "['la', 'banane', 'est', 'leur', 'fruit', 'préféré', 'moins', 'mais', 'l', 'orange', 'est', 'son', 'moins', 'préféré']\n",
      "0.7048050905062194\n",
      "['californie', 'est', 'généralement', 'enneigée', 'en', 'avril', 'et', 'il', 'fait', 'froid', 'en', 'hiver']\n",
      "['californie', 'est', 'généralement', 'enneigée', 'en', 'avril', 'et', 'il', 'fait', 'froid', 'en', 'hiver']\n",
      "1.0\n",
      "['la', 'chaux', 'est', 'son', 'fruit', 'le', 'plus', 'aimé', 'mais', 'la', 'mangue', 'est', 'mon', 'plus', 'aimé']\n",
      "['la', 'chaux', 'est', 'son', 'fruit', 'le', 'plus', 'aimé', 'mais', 'la', 'mangue', 'est', 'mon', 'plus', 'aimé']\n",
      "1.0\n",
      "['paris', 'est', 'le', 'gel', 'habituellement', 'en', 'septembre', 'mais', 'il', 'est', 'parfois', 'chaud', 'en', 'novembre']\n",
      "['paris', 'est', 'le', 'gel', 'habituellement', 'en', 'septembre', 'mais', 'il', 'est', 'parfois', 'chaud', 'en', 'novembre']\n",
      "1.0\n",
      "['la', 'pomme', 'est', 'mon', 'moins', 'aimé', 'des', 'fruits', 'mais', 'la', 'fraise', 'est', 'leur', 'moins', 'aimé']\n",
      "['la', 'pomme', 'est', 'mon', 'moins', 'aimé', 'des', 'fruits', 'mais', 'la', 'fraise', 'est', 'leur', 'moins', 'aimé']\n",
      "1.0\n",
      "['new', 'jersey', 'est', 'jamais', 'pluvieux', 'pendant', \"l'\", 'hiver', 'et', 'il', 'est', 'jamais', 'froid', 'en', 'juin']\n",
      "['new', 'jersey', 'est', 'jamais', 'pluvieux', 'pendant', 'l', 'hiver', 'et', 'il', 'est', 'jamais', 'froid', 'en', 'juin']\n",
      "0.8003203203844999\n",
      "['il', 'a', 'conduit', 'le', 'petit', 'camion', 'jaune']\n",
      "['il', 'a', 'conduit', 'le', 'petit', 'camion', 'jaune']\n",
      "1.0\n",
      "['new', 'jersey', 'est', 'relaxant', 'habituellement', 'en', 'mars', 'et', 'il', 'est', 'jamais', 'humide', 'à', \"l'\", 'automne']\n",
      "['new', 'jersey', 'est', 'relaxant', 'habituellement', 'en', 'mars', 'et', 'il', 'est', 'jamais', 'humide', 'à', 'l', 'automne']\n",
      "0.8666415730847504\n"
     ]
    }
   ],
   "source": [
    "bleu_scores = list()\n",
    "for i in range(10):\n",
    "    mystring = np.array(a)[0][i]\n",
    "    candidate = run(re.sub('\\W+',' ', mystring)).split()\n",
    "    mystring = np.array(b)[0][i]\n",
    "    reference = re.sub('\\W+',' ', mystring).split()\n",
    "    score = corpus_bleu([[reference]], [candidate])\n",
    "    print(candidate)\n",
    "    print(reference)\n",
    "    print(score)\n",
    "    bleu_scores = bleu_scores + [score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8690b6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8918934748860664"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(bleu_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b915d",
   "metadata": {},
   "source": [
    "# Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d6ca87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "Running on public URL: https://02259fd3-8385-4a42.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://02259fd3-8385-4a42.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "iface = gr.Interface(fn=run, \n",
    "                     inputs=\"text\",\n",
    "                     outputs=\"text\", \n",
    "                     description = \"This is a rudimentary English to French translator that uses Deep Learning \\\n",
    "                     (Bidirectional Recurrent Layers)\",\n",
    "                     title=\"English to French Translator\")\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3ece5",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "- Final Model Results (Avg. BLEU Score) ~0.89\n",
    "- Google Cloud's Translation has an accuracy of almost 100%. Thus our final Encoder-Decoder has proven to be almost as effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843cb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
